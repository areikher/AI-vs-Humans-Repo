{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This dataset was obtained from Kaggle (https://www.kaggle.com/datasets/pratyushpuri/ai-vs-human-content-detection-1000-record-in-2025) and contains 1,367 writing samples sourced from eight different mediums. The dataset is evenly balanced, with half of the samples authored by humans and the other half generated by AI. The objective of this project is to identify the classification model that achieves the highest accuracy in distinguishing between human- and AI-generated content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all required libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from collections import Counter\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing and Cleaning the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ai_human_content_detection_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_content</th>\n",
       "      <th>content_type</th>\n",
       "      <th>word_count</th>\n",
       "      <th>character_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>punctuation_ratio</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>gunning_fog_index</th>\n",
       "      <th>grammar_errors</th>\n",
       "      <th>passive_voice_ratio</th>\n",
       "      <th>predictability_score</th>\n",
       "      <th>burstiness</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Score each cause. Quality throughout beautiful...</td>\n",
       "      <td>academic_paper</td>\n",
       "      <td>288</td>\n",
       "      <td>1927</td>\n",
       "      <td>54</td>\n",
       "      <td>0.9514</td>\n",
       "      <td>5.33</td>\n",
       "      <td>5.69</td>\n",
       "      <td>0.0280</td>\n",
       "      <td>53.08</td>\n",
       "      <td>7.41</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1041</td>\n",
       "      <td>105.86</td>\n",
       "      <td>0.5531</td>\n",
       "      <td>0.2034</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Board its rock. Job worker break tonight coupl...</td>\n",
       "      <td>essay</td>\n",
       "      <td>253</td>\n",
       "      <td>1719</td>\n",
       "      <td>45</td>\n",
       "      <td>0.9723</td>\n",
       "      <td>5.62</td>\n",
       "      <td>5.80</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>50.32</td>\n",
       "      <td>8.10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.2045</td>\n",
       "      <td>100.29</td>\n",
       "      <td>0.5643</td>\n",
       "      <td>0.4854</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Way debate decision produce. Dream necessary c...</td>\n",
       "      <td>academic_paper</td>\n",
       "      <td>420</td>\n",
       "      <td>2849</td>\n",
       "      <td>75</td>\n",
       "      <td>0.9071</td>\n",
       "      <td>5.60</td>\n",
       "      <td>5.79</td>\n",
       "      <td>0.0263</td>\n",
       "      <td>46.86</td>\n",
       "      <td>7.86</td>\n",
       "      <td>5</td>\n",
       "      <td>0.2308</td>\n",
       "      <td>96.88</td>\n",
       "      <td>0.4979</td>\n",
       "      <td>-0.2369</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Story turn because such during open model. Tha...</td>\n",
       "      <td>creative_writing</td>\n",
       "      <td>196</td>\n",
       "      <td>1310</td>\n",
       "      <td>34</td>\n",
       "      <td>0.9592</td>\n",
       "      <td>5.76</td>\n",
       "      <td>5.69</td>\n",
       "      <td>0.0260</td>\n",
       "      <td>53.80</td>\n",
       "      <td>7.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1912</td>\n",
       "      <td>88.79</td>\n",
       "      <td>0.6241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Place specific as simply leader fall analysis....</td>\n",
       "      <td>news_article</td>\n",
       "      <td>160</td>\n",
       "      <td>1115</td>\n",
       "      <td>28</td>\n",
       "      <td>0.9688</td>\n",
       "      <td>5.71</td>\n",
       "      <td>5.97</td>\n",
       "      <td>0.0251</td>\n",
       "      <td>44.53</td>\n",
       "      <td>8.29</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1318</td>\n",
       "      <td>26.15</td>\n",
       "      <td>0.2894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>Congress month from thought instead anything. ...</td>\n",
       "      <td>academic_paper</td>\n",
       "      <td>251</td>\n",
       "      <td>1677</td>\n",
       "      <td>44</td>\n",
       "      <td>0.9721</td>\n",
       "      <td>5.70</td>\n",
       "      <td>5.69</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>50.72</td>\n",
       "      <td>8.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1232</td>\n",
       "      <td>112.37</td>\n",
       "      <td>0.6893</td>\n",
       "      <td>0.2415</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363</th>\n",
       "      <td>Learn lead reveal great action. Left theory pa...</td>\n",
       "      <td>article</td>\n",
       "      <td>79</td>\n",
       "      <td>503</td>\n",
       "      <td>15</td>\n",
       "      <td>0.9620</td>\n",
       "      <td>5.27</td>\n",
       "      <td>5.38</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>60.13</td>\n",
       "      <td>6.16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2369</td>\n",
       "      <td>111.76</td>\n",
       "      <td>0.6263</td>\n",
       "      <td>-0.8244</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364</th>\n",
       "      <td>Third few low hard peace paper pass front. Mea...</td>\n",
       "      <td>social_media</td>\n",
       "      <td>15</td>\n",
       "      <td>94</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.33</td>\n",
       "      <td>0.0319</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1296</td>\n",
       "      <td>37.37</td>\n",
       "      <td>0.2182</td>\n",
       "      <td>0.8319</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365</th>\n",
       "      <td>Power word west very news. Truth action base p...</td>\n",
       "      <td>blog_post</td>\n",
       "      <td>92</td>\n",
       "      <td>578</td>\n",
       "      <td>14</td>\n",
       "      <td>0.9891</td>\n",
       "      <td>6.57</td>\n",
       "      <td>5.29</td>\n",
       "      <td>0.0242</td>\n",
       "      <td>61.31</td>\n",
       "      <td>7.41</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1898</td>\n",
       "      <td>46.58</td>\n",
       "      <td>0.1151</td>\n",
       "      <td>0.1486</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1366</th>\n",
       "      <td>Beyond card must former. Leave where join kind...</td>\n",
       "      <td>blog_post</td>\n",
       "      <td>192</td>\n",
       "      <td>1270</td>\n",
       "      <td>34</td>\n",
       "      <td>0.9844</td>\n",
       "      <td>5.65</td>\n",
       "      <td>5.62</td>\n",
       "      <td>0.0268</td>\n",
       "      <td>49.09</td>\n",
       "      <td>7.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0762</td>\n",
       "      <td>25.94</td>\n",
       "      <td>0.2506</td>\n",
       "      <td>0.8069</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1367 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           text_content      content_type  \\\n",
       "0     Score each cause. Quality throughout beautiful...    academic_paper   \n",
       "1     Board its rock. Job worker break tonight coupl...             essay   \n",
       "2     Way debate decision produce. Dream necessary c...    academic_paper   \n",
       "3     Story turn because such during open model. Tha...  creative_writing   \n",
       "4     Place specific as simply leader fall analysis....      news_article   \n",
       "...                                                 ...               ...   \n",
       "1362  Congress month from thought instead anything. ...    academic_paper   \n",
       "1363  Learn lead reveal great action. Left theory pa...           article   \n",
       "1364  Third few low hard peace paper pass front. Mea...      social_media   \n",
       "1365  Power word west very news. Truth action base p...         blog_post   \n",
       "1366  Beyond card must former. Leave where join kind...         blog_post   \n",
       "\n",
       "      word_count  character_count  sentence_count  lexical_diversity  \\\n",
       "0            288             1927              54             0.9514   \n",
       "1            253             1719              45             0.9723   \n",
       "2            420             2849              75             0.9071   \n",
       "3            196             1310              34             0.9592   \n",
       "4            160             1115              28             0.9688   \n",
       "...          ...              ...             ...                ...   \n",
       "1362         251             1677              44             0.9721   \n",
       "1363          79              503              15             0.9620   \n",
       "1364          15               94               3             1.0000   \n",
       "1365          92              578              14             0.9891   \n",
       "1366         192             1270              34             0.9844   \n",
       "\n",
       "      avg_sentence_length  avg_word_length  punctuation_ratio  \\\n",
       "0                    5.33             5.69             0.0280   \n",
       "1                    5.62             5.80             0.0262   \n",
       "2                    5.60             5.79             0.0263   \n",
       "3                    5.76             5.69             0.0260   \n",
       "4                    5.71             5.97             0.0251   \n",
       "...                   ...              ...                ...   \n",
       "1362                 5.70             5.69             0.0262   \n",
       "1363                 5.27             5.38             0.0298   \n",
       "1364                 5.00             5.33             0.0319   \n",
       "1365                 6.57             5.29             0.0242   \n",
       "1366                 5.65             5.62             0.0268   \n",
       "\n",
       "      flesch_reading_ease  gunning_fog_index  grammar_errors  \\\n",
       "0                   53.08               7.41               1   \n",
       "1                   50.32               8.10               6   \n",
       "2                   46.86               7.86               5   \n",
       "3                   53.80               7.00               2   \n",
       "4                   44.53               8.29               0   \n",
       "...                   ...                ...             ...   \n",
       "1362                50.72               8.02               0   \n",
       "1363                60.13               6.16               0   \n",
       "1364                  NaN               4.67               0   \n",
       "1365                61.31               7.41               0   \n",
       "1366                49.09               7.88               0   \n",
       "\n",
       "      passive_voice_ratio  predictability_score  burstiness  sentiment_score  \\\n",
       "0                  0.1041                105.86      0.5531           0.2034   \n",
       "1                  0.2045                100.29      0.5643           0.4854   \n",
       "2                  0.2308                 96.88      0.4979          -0.2369   \n",
       "3                  0.1912                 88.79      0.6241              NaN   \n",
       "4                  0.1318                 26.15      0.2894              NaN   \n",
       "...                   ...                   ...         ...              ...   \n",
       "1362               0.1232                112.37      0.6893           0.2415   \n",
       "1363               0.2369                111.76      0.6263          -0.8244   \n",
       "1364               0.1296                 37.37      0.2182           0.8319   \n",
       "1365               0.1898                 46.58      0.1151           0.1486   \n",
       "1366               0.0762                 25.94      0.2506           0.8069   \n",
       "\n",
       "      label  \n",
       "0         1  \n",
       "1         1  \n",
       "2         1  \n",
       "3         1  \n",
       "4         1  \n",
       "...     ...  \n",
       "1362      0  \n",
       "1363      0  \n",
       "1364      0  \n",
       "1365      0  \n",
       "1366      0  \n",
       "\n",
       "[1367 rows x 17 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizes the text data using TD-IDF and removed stope words\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "tfidf_matrix = vectorizer.fit_transform(df[\"text_content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a dataframe from the vectorized matrix\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>accept</th>\n",
       "      <th>according</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>activity</th>\n",
       "      <th>actually</th>\n",
       "      <th>add</th>\n",
       "      <th>...</th>\n",
       "      <th>world</th>\n",
       "      <th>worry</th>\n",
       "      <th>write</th>\n",
       "      <th>writer</th>\n",
       "      <th>wrong</th>\n",
       "      <th>yard</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059526</td>\n",
       "      <td>0.060724</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060837</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061845</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064767</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045570</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.087348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046617</td>\n",
       "      <td>0.045655</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044671</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.072535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.077656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066075</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068537</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066428</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.118339</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.113366</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1366</th>\n",
       "      <td>0.156879</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075785</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1367 rows × 763 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ability  able    accept  according   account       act    action  \\\n",
       "0     0.000000   0.0  0.000000   0.059526  0.060724  0.000000  0.000000   \n",
       "1     0.000000   0.0  0.000000   0.000000  0.000000  0.061845  0.000000   \n",
       "2     0.000000   0.0  0.000000   0.000000  0.045570  0.000000  0.000000   \n",
       "3     0.072535   0.0  0.000000   0.000000  0.000000  0.000000  0.000000   \n",
       "4     0.000000   0.0  0.000000   0.000000  0.000000  0.000000  0.000000   \n",
       "...        ...   ...       ...        ...       ...       ...       ...   \n",
       "1362  0.000000   0.0  0.000000   0.066310  0.000000  0.066075  0.000000   \n",
       "1363  0.000000   0.0  0.000000   0.000000  0.000000  0.000000  0.118339   \n",
       "1364  0.000000   0.0  0.000000   0.000000  0.000000  0.000000  0.000000   \n",
       "1365  0.000000   0.0  0.000000   0.000000  0.000000  0.000000  0.113366   \n",
       "1366  0.156879   0.0  0.078147   0.000000  0.077857  0.000000  0.000000   \n",
       "\n",
       "      activity  actually       add  ...     world  worry     write    writer  \\\n",
       "0     0.000000       0.0  0.000000  ...  0.119265    0.0  0.000000  0.060837   \n",
       "1     0.064149       0.0  0.000000  ...  0.000000    0.0  0.064767  0.000000   \n",
       "2     0.000000       0.0  0.087348  ...  0.000000    0.0  0.046617  0.045655   \n",
       "3     0.000000       0.0  0.000000  ...  0.000000    0.0  0.073650  0.000000   \n",
       "4     0.000000       0.0  0.000000  ...  0.000000    0.0  0.000000  0.000000   \n",
       "...        ...       ...       ...  ...       ...    ...       ...       ...   \n",
       "1362  0.068537       0.0  0.000000  ...  0.066428    0.0  0.000000  0.000000   \n",
       "1363  0.000000       0.0  0.000000  ...  0.000000    0.0  0.000000  0.000000   \n",
       "1364  0.000000       0.0  0.000000  ...  0.000000    0.0  0.000000  0.000000   \n",
       "1365  0.000000       0.0  0.000000  ...  0.000000    0.0  0.000000  0.112733   \n",
       "1366  0.078885       0.0  0.000000  ...  0.000000    0.0  0.000000  0.000000   \n",
       "\n",
       "      wrong      yard      yeah      year  yes     young  \n",
       "0       0.0  0.000000  0.000000  0.000000  0.0  0.058800  \n",
       "1       0.0  0.000000  0.000000  0.000000  0.0  0.000000  \n",
       "2       0.0  0.000000  0.044671  0.000000  0.0  0.044126  \n",
       "3       0.0  0.000000  0.000000  0.000000  0.0  0.000000  \n",
       "4       0.0  0.000000  0.000000  0.000000  0.0  0.077656  \n",
       "...     ...       ...       ...       ...  ...       ...  \n",
       "1362    0.0  0.000000  0.000000  0.000000  0.0  0.000000  \n",
       "1363    0.0  0.000000  0.000000  0.000000  0.0  0.000000  \n",
       "1364    0.0  0.000000  0.000000  0.000000  0.0  0.000000  \n",
       "1365    0.0  0.000000  0.000000  0.000000  0.0  0.000000  \n",
       "1366    0.0  0.078002  0.000000  0.075785  0.0  0.000000  \n",
       "\n",
       "[1367 rows x 763 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['academic_paper', 'essay', 'creative_writing', 'news_article',\n",
       "       'blog_post', 'article', 'social_media', 'product_review'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['content_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "contentDict = {\n",
    "    'academic_paper':1,\n",
    "    'essay':2,\n",
    "    'creative_writing':3,\n",
    "    'news_article':4,\n",
    "    'blog_post':5,\n",
    "    'article':6,\n",
    "    'social_media':7,\n",
    "    'product_review':8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to be able to use the 'content_type' column in the dataframe, you would need to assign it a numerical value \n",
    "#in order to be represented in the data model\n",
    "contentLst = []\n",
    "\n",
    "for i in df['content_type']:\n",
    "    contentLst.append(contentDict[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Content_num'] = contentLst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_content</th>\n",
       "      <th>content_type</th>\n",
       "      <th>word_count</th>\n",
       "      <th>character_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>punctuation_ratio</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>gunning_fog_index</th>\n",
       "      <th>grammar_errors</th>\n",
       "      <th>passive_voice_ratio</th>\n",
       "      <th>predictability_score</th>\n",
       "      <th>burstiness</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>label</th>\n",
       "      <th>Content_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Score each cause. Quality throughout beautiful...</td>\n",
       "      <td>academic_paper</td>\n",
       "      <td>288</td>\n",
       "      <td>1927</td>\n",
       "      <td>54</td>\n",
       "      <td>0.9514</td>\n",
       "      <td>5.33</td>\n",
       "      <td>5.69</td>\n",
       "      <td>0.0280</td>\n",
       "      <td>53.08</td>\n",
       "      <td>7.41</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1041</td>\n",
       "      <td>105.86</td>\n",
       "      <td>0.5531</td>\n",
       "      <td>0.2034</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Board its rock. Job worker break tonight coupl...</td>\n",
       "      <td>essay</td>\n",
       "      <td>253</td>\n",
       "      <td>1719</td>\n",
       "      <td>45</td>\n",
       "      <td>0.9723</td>\n",
       "      <td>5.62</td>\n",
       "      <td>5.80</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>50.32</td>\n",
       "      <td>8.10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.2045</td>\n",
       "      <td>100.29</td>\n",
       "      <td>0.5643</td>\n",
       "      <td>0.4854</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Way debate decision produce. Dream necessary c...</td>\n",
       "      <td>academic_paper</td>\n",
       "      <td>420</td>\n",
       "      <td>2849</td>\n",
       "      <td>75</td>\n",
       "      <td>0.9071</td>\n",
       "      <td>5.60</td>\n",
       "      <td>5.79</td>\n",
       "      <td>0.0263</td>\n",
       "      <td>46.86</td>\n",
       "      <td>7.86</td>\n",
       "      <td>5</td>\n",
       "      <td>0.2308</td>\n",
       "      <td>96.88</td>\n",
       "      <td>0.4979</td>\n",
       "      <td>-0.2369</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Story turn because such during open model. Tha...</td>\n",
       "      <td>creative_writing</td>\n",
       "      <td>196</td>\n",
       "      <td>1310</td>\n",
       "      <td>34</td>\n",
       "      <td>0.9592</td>\n",
       "      <td>5.76</td>\n",
       "      <td>5.69</td>\n",
       "      <td>0.0260</td>\n",
       "      <td>53.80</td>\n",
       "      <td>7.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1912</td>\n",
       "      <td>88.79</td>\n",
       "      <td>0.6241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Place specific as simply leader fall analysis....</td>\n",
       "      <td>news_article</td>\n",
       "      <td>160</td>\n",
       "      <td>1115</td>\n",
       "      <td>28</td>\n",
       "      <td>0.9688</td>\n",
       "      <td>5.71</td>\n",
       "      <td>5.97</td>\n",
       "      <td>0.0251</td>\n",
       "      <td>44.53</td>\n",
       "      <td>8.29</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1318</td>\n",
       "      <td>26.15</td>\n",
       "      <td>0.2894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>Congress month from thought instead anything. ...</td>\n",
       "      <td>academic_paper</td>\n",
       "      <td>251</td>\n",
       "      <td>1677</td>\n",
       "      <td>44</td>\n",
       "      <td>0.9721</td>\n",
       "      <td>5.70</td>\n",
       "      <td>5.69</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>50.72</td>\n",
       "      <td>8.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1232</td>\n",
       "      <td>112.37</td>\n",
       "      <td>0.6893</td>\n",
       "      <td>0.2415</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363</th>\n",
       "      <td>Learn lead reveal great action. Left theory pa...</td>\n",
       "      <td>article</td>\n",
       "      <td>79</td>\n",
       "      <td>503</td>\n",
       "      <td>15</td>\n",
       "      <td>0.9620</td>\n",
       "      <td>5.27</td>\n",
       "      <td>5.38</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>60.13</td>\n",
       "      <td>6.16</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2369</td>\n",
       "      <td>111.76</td>\n",
       "      <td>0.6263</td>\n",
       "      <td>-0.8244</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364</th>\n",
       "      <td>Third few low hard peace paper pass front. Mea...</td>\n",
       "      <td>social_media</td>\n",
       "      <td>15</td>\n",
       "      <td>94</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.33</td>\n",
       "      <td>0.0319</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1296</td>\n",
       "      <td>37.37</td>\n",
       "      <td>0.2182</td>\n",
       "      <td>0.8319</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365</th>\n",
       "      <td>Power word west very news. Truth action base p...</td>\n",
       "      <td>blog_post</td>\n",
       "      <td>92</td>\n",
       "      <td>578</td>\n",
       "      <td>14</td>\n",
       "      <td>0.9891</td>\n",
       "      <td>6.57</td>\n",
       "      <td>5.29</td>\n",
       "      <td>0.0242</td>\n",
       "      <td>61.31</td>\n",
       "      <td>7.41</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1898</td>\n",
       "      <td>46.58</td>\n",
       "      <td>0.1151</td>\n",
       "      <td>0.1486</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1366</th>\n",
       "      <td>Beyond card must former. Leave where join kind...</td>\n",
       "      <td>blog_post</td>\n",
       "      <td>192</td>\n",
       "      <td>1270</td>\n",
       "      <td>34</td>\n",
       "      <td>0.9844</td>\n",
       "      <td>5.65</td>\n",
       "      <td>5.62</td>\n",
       "      <td>0.0268</td>\n",
       "      <td>49.09</td>\n",
       "      <td>7.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0762</td>\n",
       "      <td>25.94</td>\n",
       "      <td>0.2506</td>\n",
       "      <td>0.8069</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1367 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           text_content      content_type  \\\n",
       "0     Score each cause. Quality throughout beautiful...    academic_paper   \n",
       "1     Board its rock. Job worker break tonight coupl...             essay   \n",
       "2     Way debate decision produce. Dream necessary c...    academic_paper   \n",
       "3     Story turn because such during open model. Tha...  creative_writing   \n",
       "4     Place specific as simply leader fall analysis....      news_article   \n",
       "...                                                 ...               ...   \n",
       "1362  Congress month from thought instead anything. ...    academic_paper   \n",
       "1363  Learn lead reveal great action. Left theory pa...           article   \n",
       "1364  Third few low hard peace paper pass front. Mea...      social_media   \n",
       "1365  Power word west very news. Truth action base p...         blog_post   \n",
       "1366  Beyond card must former. Leave where join kind...         blog_post   \n",
       "\n",
       "      word_count  character_count  sentence_count  lexical_diversity  \\\n",
       "0            288             1927              54             0.9514   \n",
       "1            253             1719              45             0.9723   \n",
       "2            420             2849              75             0.9071   \n",
       "3            196             1310              34             0.9592   \n",
       "4            160             1115              28             0.9688   \n",
       "...          ...              ...             ...                ...   \n",
       "1362         251             1677              44             0.9721   \n",
       "1363          79              503              15             0.9620   \n",
       "1364          15               94               3             1.0000   \n",
       "1365          92              578              14             0.9891   \n",
       "1366         192             1270              34             0.9844   \n",
       "\n",
       "      avg_sentence_length  avg_word_length  punctuation_ratio  \\\n",
       "0                    5.33             5.69             0.0280   \n",
       "1                    5.62             5.80             0.0262   \n",
       "2                    5.60             5.79             0.0263   \n",
       "3                    5.76             5.69             0.0260   \n",
       "4                    5.71             5.97             0.0251   \n",
       "...                   ...              ...                ...   \n",
       "1362                 5.70             5.69             0.0262   \n",
       "1363                 5.27             5.38             0.0298   \n",
       "1364                 5.00             5.33             0.0319   \n",
       "1365                 6.57             5.29             0.0242   \n",
       "1366                 5.65             5.62             0.0268   \n",
       "\n",
       "      flesch_reading_ease  gunning_fog_index  grammar_errors  \\\n",
       "0                   53.08               7.41               1   \n",
       "1                   50.32               8.10               6   \n",
       "2                   46.86               7.86               5   \n",
       "3                   53.80               7.00               2   \n",
       "4                   44.53               8.29               0   \n",
       "...                   ...                ...             ...   \n",
       "1362                50.72               8.02               0   \n",
       "1363                60.13               6.16               0   \n",
       "1364                  NaN               4.67               0   \n",
       "1365                61.31               7.41               0   \n",
       "1366                49.09               7.88               0   \n",
       "\n",
       "      passive_voice_ratio  predictability_score  burstiness  sentiment_score  \\\n",
       "0                  0.1041                105.86      0.5531           0.2034   \n",
       "1                  0.2045                100.29      0.5643           0.4854   \n",
       "2                  0.2308                 96.88      0.4979          -0.2369   \n",
       "3                  0.1912                 88.79      0.6241              NaN   \n",
       "4                  0.1318                 26.15      0.2894              NaN   \n",
       "...                   ...                   ...         ...              ...   \n",
       "1362               0.1232                112.37      0.6893           0.2415   \n",
       "1363               0.2369                111.76      0.6263          -0.8244   \n",
       "1364               0.1296                 37.37      0.2182           0.8319   \n",
       "1365               0.1898                 46.58      0.1151           0.1486   \n",
       "1366               0.0762                 25.94      0.2506           0.8069   \n",
       "\n",
       "      label  Content_num  \n",
       "0         1            1  \n",
       "1         1            2  \n",
       "2         1            1  \n",
       "3         1            3  \n",
       "4         1            4  \n",
       "...     ...          ...  \n",
       "1362      0            1  \n",
       "1363      0            6  \n",
       "1364      0            7  \n",
       "1365      0            5  \n",
       "1366      0            5  \n",
       "\n",
       "[1367 rows x 18 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging the two dataframes so that you have both the original information and the TD-IDF data\n",
    "merged_df = pd.merge(df, tfidf_df, left_index=True, right_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.drop(['text_content', 'content_type'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>character_count</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>punctuation_ratio</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>gunning_fog_index</th>\n",
       "      <th>grammar_errors</th>\n",
       "      <th>...</th>\n",
       "      <th>world</th>\n",
       "      <th>worry</th>\n",
       "      <th>write</th>\n",
       "      <th>writer</th>\n",
       "      <th>wrong</th>\n",
       "      <th>yard</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>288</td>\n",
       "      <td>1927</td>\n",
       "      <td>54</td>\n",
       "      <td>0.9514</td>\n",
       "      <td>5.33</td>\n",
       "      <td>5.69</td>\n",
       "      <td>0.0280</td>\n",
       "      <td>53.08</td>\n",
       "      <td>7.41</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060837</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>253</td>\n",
       "      <td>1719</td>\n",
       "      <td>45</td>\n",
       "      <td>0.9723</td>\n",
       "      <td>5.62</td>\n",
       "      <td>5.80</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>50.32</td>\n",
       "      <td>8.10</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064767</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>420</td>\n",
       "      <td>2849</td>\n",
       "      <td>75</td>\n",
       "      <td>0.9071</td>\n",
       "      <td>5.60</td>\n",
       "      <td>5.79</td>\n",
       "      <td>0.0263</td>\n",
       "      <td>46.86</td>\n",
       "      <td>7.86</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.046617</td>\n",
       "      <td>0.045655</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044671</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>196</td>\n",
       "      <td>1310</td>\n",
       "      <td>34</td>\n",
       "      <td>0.9592</td>\n",
       "      <td>5.76</td>\n",
       "      <td>5.69</td>\n",
       "      <td>0.0260</td>\n",
       "      <td>53.80</td>\n",
       "      <td>7.00</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>160</td>\n",
       "      <td>1115</td>\n",
       "      <td>28</td>\n",
       "      <td>0.9688</td>\n",
       "      <td>5.71</td>\n",
       "      <td>5.97</td>\n",
       "      <td>0.0251</td>\n",
       "      <td>44.53</td>\n",
       "      <td>8.29</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.077656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>251</td>\n",
       "      <td>1677</td>\n",
       "      <td>44</td>\n",
       "      <td>0.9721</td>\n",
       "      <td>5.70</td>\n",
       "      <td>5.69</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>50.72</td>\n",
       "      <td>8.02</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066428</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363</th>\n",
       "      <td>79</td>\n",
       "      <td>503</td>\n",
       "      <td>15</td>\n",
       "      <td>0.9620</td>\n",
       "      <td>5.27</td>\n",
       "      <td>5.38</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>60.13</td>\n",
       "      <td>6.16</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364</th>\n",
       "      <td>15</td>\n",
       "      <td>94</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.33</td>\n",
       "      <td>0.0319</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.67</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365</th>\n",
       "      <td>92</td>\n",
       "      <td>578</td>\n",
       "      <td>14</td>\n",
       "      <td>0.9891</td>\n",
       "      <td>6.57</td>\n",
       "      <td>5.29</td>\n",
       "      <td>0.0242</td>\n",
       "      <td>61.31</td>\n",
       "      <td>7.41</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1366</th>\n",
       "      <td>192</td>\n",
       "      <td>1270</td>\n",
       "      <td>34</td>\n",
       "      <td>0.9844</td>\n",
       "      <td>5.65</td>\n",
       "      <td>5.62</td>\n",
       "      <td>0.0268</td>\n",
       "      <td>49.09</td>\n",
       "      <td>7.88</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075785</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1367 rows × 779 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      word_count  character_count  sentence_count  lexical_diversity  \\\n",
       "0            288             1927              54             0.9514   \n",
       "1            253             1719              45             0.9723   \n",
       "2            420             2849              75             0.9071   \n",
       "3            196             1310              34             0.9592   \n",
       "4            160             1115              28             0.9688   \n",
       "...          ...              ...             ...                ...   \n",
       "1362         251             1677              44             0.9721   \n",
       "1363          79              503              15             0.9620   \n",
       "1364          15               94               3             1.0000   \n",
       "1365          92              578              14             0.9891   \n",
       "1366         192             1270              34             0.9844   \n",
       "\n",
       "      avg_sentence_length  avg_word_length  punctuation_ratio  \\\n",
       "0                    5.33             5.69             0.0280   \n",
       "1                    5.62             5.80             0.0262   \n",
       "2                    5.60             5.79             0.0263   \n",
       "3                    5.76             5.69             0.0260   \n",
       "4                    5.71             5.97             0.0251   \n",
       "...                   ...              ...                ...   \n",
       "1362                 5.70             5.69             0.0262   \n",
       "1363                 5.27             5.38             0.0298   \n",
       "1364                 5.00             5.33             0.0319   \n",
       "1365                 6.57             5.29             0.0242   \n",
       "1366                 5.65             5.62             0.0268   \n",
       "\n",
       "      flesch_reading_ease  gunning_fog_index  grammar_errors  ...     world  \\\n",
       "0                   53.08               7.41               1  ...  0.119265   \n",
       "1                   50.32               8.10               6  ...  0.000000   \n",
       "2                   46.86               7.86               5  ...  0.000000   \n",
       "3                   53.80               7.00               2  ...  0.000000   \n",
       "4                   44.53               8.29               0  ...  0.000000   \n",
       "...                   ...                ...             ...  ...       ...   \n",
       "1362                50.72               8.02               0  ...  0.066428   \n",
       "1363                60.13               6.16               0  ...  0.000000   \n",
       "1364                  NaN               4.67               0  ...  0.000000   \n",
       "1365                61.31               7.41               0  ...  0.000000   \n",
       "1366                49.09               7.88               0  ...  0.000000   \n",
       "\n",
       "      worry     write    writer  wrong      yard      yeah      year  yes  \\\n",
       "0       0.0  0.000000  0.060837    0.0  0.000000  0.000000  0.000000  0.0   \n",
       "1       0.0  0.064767  0.000000    0.0  0.000000  0.000000  0.000000  0.0   \n",
       "2       0.0  0.046617  0.045655    0.0  0.000000  0.044671  0.000000  0.0   \n",
       "3       0.0  0.073650  0.000000    0.0  0.000000  0.000000  0.000000  0.0   \n",
       "4       0.0  0.000000  0.000000    0.0  0.000000  0.000000  0.000000  0.0   \n",
       "...     ...       ...       ...    ...       ...       ...       ...  ...   \n",
       "1362    0.0  0.000000  0.000000    0.0  0.000000  0.000000  0.000000  0.0   \n",
       "1363    0.0  0.000000  0.000000    0.0  0.000000  0.000000  0.000000  0.0   \n",
       "1364    0.0  0.000000  0.000000    0.0  0.000000  0.000000  0.000000  0.0   \n",
       "1365    0.0  0.000000  0.112733    0.0  0.000000  0.000000  0.000000  0.0   \n",
       "1366    0.0  0.000000  0.000000    0.0  0.078002  0.000000  0.075785  0.0   \n",
       "\n",
       "         young  \n",
       "0     0.058800  \n",
       "1     0.000000  \n",
       "2     0.044126  \n",
       "3     0.000000  \n",
       "4     0.077656  \n",
       "...        ...  \n",
       "1362  0.000000  \n",
       "1363  0.000000  \n",
       "1364  0.000000  \n",
       "1365  0.000000  \n",
       "1366  0.000000  \n",
       "\n",
       "[1367 rows x 779 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 683\n",
      "0: 684\n"
     ]
    }
   ],
   "source": [
    "#verifying that the labels are balanced\n",
    "print('1:',sum(merged_df['label']))\n",
    "print('0:', 1367 - sum(merged_df['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merged_df.drop(['label'], axis=1)\n",
    "y = merged_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 51.09%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='Blues', cbar=False)\n",
    "\n",
    "plt.title('Confusion Matrix Heatmap')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "        'n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
    "        'max_depth': [None, 10, 20],      # Maximum depth of the tree\n",
    "        'min_samples_leaf': [1, 2, 4],    # Minimum number of samples required to be at a leaf node\n",
    "        'criterion': ['gini', 'entropy']  # Function to measure the quality of a split\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator=classifier, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [None, 10, 20],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300]},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [None, 10, 20],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300]},\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [None, 10, 20],\n",
       "                         'min_samples_leaf': [1, 2, 4],\n",
       "                         'n_estimators': [100, 200, 300]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 2, 'n_estimators': 100}\n",
      "Best cross-validation score:  0.5260818566461396\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score of the best model:  0.5072992700729927\n"
     ]
    }
   ],
   "source": [
    "best_rf_model = grid_search.best_estimator_\n",
    "test_score = best_rf_model.score(X_test, y_test)\n",
    "print(\"Test set score of the best model: \", test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(random_state=1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4854014598540146\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = dtc.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='Blues', cbar=False)\n",
    "\n",
    "plt.title('Confusion Matrix Heatmap')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1620 candidates, totalling 8100 fits\n",
      "best accuracy 0.5187842989401366\n",
      "DecisionTreeClassifier(max_depth=6, min_samples_leaf=13, random_state=1)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'max_depth': range(1, 10, 1),\n",
    "    'min_samples_leaf': range(1, 20, 2),\n",
    "    'min_samples_split': range(2, 20, 2),\n",
    "    'criterion': [\"entropy\", \"gini\"]\n",
    "}\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=tree, param_grid=param_grid, \n",
    "                           cv=5, verbose=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"best accuracy\", grid_search.best_score_)\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score of the best model:  0.5072992700729927\n"
     ]
    }
   ],
   "source": [
    "best_dtc_model = grid_search.best_estimator_\n",
    "test_score = best_dtc_model.score(X_test, y_test)\n",
    "print(\"Test set score of the best model: \", test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7591\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(kernel=\"linear\", C=1)\n",
    "svm.fit(X, y)\n",
    "\n",
    "y_pred = svm.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "#cv_scores = cross_val_score(svm, X, y, cv=5)  # returns scores for each fold\n",
    "#print(f\"Cross-validation scores: {cv_scores}\")\n",
    "#print(f\"Mean CV accuracy: {cv_scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5182481751824818\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression model accuracy: 50.73%\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=10000, random_state=0)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "acc = accuracy_score(y_test, lr.predict(X_test)) * 100\n",
    "print(f\"Logistic Regression model accuracy: {acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5109489051094891\n",
      "F1 Score: 0.5112621818477951\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = nb.predict(X_test)\n",
    "accuray = accuracy_score(y_pred, y_test)\n",
    "f1 = f1_score(y_pred, y_test, average=\"weighted\")\n",
    "\n",
    "print(\"Accuracy:\", accuray)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Conclusion\n",
    "\n",
    "Among the six most common classification models evaluated, the Support Vector Machine (SVM) achieved the highest accuracy. The other five models yielded accuracies near 50%, which is essentially equivalent to random chance. While the SVM demonstrated superior predictive performance, it also required the longest execution time, with a runtime of approximately 40 minutes.\n",
    "\n",
    "As a next step, the SVM model should be saved for future use and applied to additional datasets to evaluate its generalizability and performance across different data sources."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
